{
  "diarization": {
    "SPEAKER_00": 142
  },
  "asr": {
    " I would like to tell you a story connecting the notorious privacy incident involving Adam and Eve.": 1,
    " And the remarkable shift in the boundaries between public and private, which has occurred in the past ten years.": 1,
    " You know the incident, Adam and Eve, one day, in the Garden of Eden, realize they are naked, they freak out, and the rest is history.": 1,
    " Nowadays, Adam and Eve would probably act differently.": 1,
    " We do reveal so much more information about ourselves online than ever before.": 1,
    "So much information about us is being collected by organizations now.": 1,
    " There is much to gain and benefit from this massive analysis of personal information or big data.": 1,
    "But there are also complex trade-offs that come from giving away our privacy.": 1,
    " And my story is about these trade-offs.": 1,
    " We start with an observation, which in my mind has become clearer and clearer in the past few years, that any personal information can become sensitive information.": 1,
    " Back in the year 2000, about 100 billion photos were shot worldwide, but only a miniscule proportion of them were actually uploaded online.": 1,
    " In 2010, only on Facebook, in a single month, 2.5 billion photos were uploaded.": 1,
    "Most of them identified.": 1,
    " In the same span of time, computers' ability to recognize people in photos improved by three orders of magnitude.": 1,
    " What happens when you combine these technologies together?": 1,
    "Increasing availability of facial data, improving facial recognising ability by computers, but also": 1,
    " Cloud computing, which gives anyone in this theater the kind of computational power which a few years ago was only the domain of three-letter agencies.": 1,
    "And ubiquitous computing, which allows my phone, which is not a super computer, to connect to the internet": 1,
    " and do there hundreds of thousands of face matches in a few seconds.": 1,
    "Well, we conjecture the result of this combination of technologies will be a radical change in our very notions of privacy and anonymity.": 1,
    " To test that, we did an experiment on Carnegie Mellon University campus.": 1,
    "We asked students who were walking by to participate in a study.": 1,
    "And we took a shot with a webcam.": 1,
    " and we asked them to fill out a survey on a laptop.": 1,
    "While they were filling out the survey, we uploaded their shot to a cloud computing cluster, and we started using a facial recognizer to match that shot": 1,
    " to a database of some hundreds of thousands of images which we had downloaded from Facebook profiles.": 1,
    " By the time the subject reached the last page on the survey, the page had been dynamically updated with the 10 best matching photos which the recognizer had found.": 1,
    " and we ask the subjects to indicate whether he or she found themselves in the photo.": 1,
    " Do you see the subject?": 1,
    " Well, the computer did, and in fact did so for one out of three subjects.": 1,
    " So essentially, we can start from an anonymous face, offline or online, and we can use facial recognition to give a name to that anonymous face thanks to social media data.": 1,
    " But a few years back, we did something else.": 1,
    "We started from social media data, we combined it statistically with data from US government social security, and we ended up predicting social security numbers, which in the United States are extremely sensitive.": 1,
    " Do you see where I'm going with this?": 1,
    " So if you combine the two studies together, then the question becomes, can you start from a phase?": 1,
    "And using facial recognition, find a name and publicly available information about that name and that person.": 1,
    " And from that publicly-valued information infer non-publicly-valued information, much more sensitive ones, which you link back to the face.": 1,
    "And the answer is yes, we can and we did.": 1,
    "Of course, the accuracy keeps getting worse.": 1,
    " But in fact, we even decided to develop an iPhone app which uses the phone internal camera to take a shot of a subject and then upload it to a cloud and then do what I just described to you in real time.": 1,
    " looking for a match, finding public information, trying to infer sensitive information, and then sending it back to the phone so that it is overlaid on the face of the subject, an example of augmented reality, probably a creepy example of augmented reality.": 1,
    " We didn't develop the app to make it available, just as a proof of concept.": 1,
    "In fact, take these technologies and push them to their logical extreme.": 1,
    "Imagine a future in which": 1,
    " strangers around you will look at you through their Google glasses or one day their contact lenses and use seven or eight data points about you to infer anything else which may be known about you.": 1,
    " What will this future with our secrets look like?": 1,
    "And should we care?": 1,
    "We may like to believe that the future with so much wealth of data will be a future with no more biases.": 1,
    " But in fact, having so much information doesn't mean that we will make decisions which are more objective.": 1,
    "In another experiment, we presented to our subjects information about a potential job candidate.": 1,
    " We included in this information some references to some funny, absolutely legal, but perhaps slightly embarrassing information that the subject had posted online.": 1,
    " Now, interestingly, among our subjects, some had posted comparable information and some had not.": 1,
    " Which group do you think was more likely to judge harshly our subject?": 1,
    " Paradoxically, it was the group who had posted similar information, an example of moral dissonance.": 1,
    "Now, you may be thinking, this does not apply to me because I have nothing to hide.": 1,
    " But in fact, privacy is not about having something negative to hide.": 1,
    "Imagine that you are the HR director of a certain organization and you receive": 1,
    " Resumes and you decide to find more information about the candidates.": 1,
    "Therefore you Google their names and In a certain universe you find this information or in a parallel universe you find this information": 1,
    " Do you think that you will be equally likely to call either candidate for an interview?": 1,
    " If you think so, then you are not like the US employers who are in fact part of our experiment, meaning we did exactly that.": 1,
    "We created Facebook profiles, manipulating trades, and then we started sending out resumes to companies in the US.": 1,
    " and we detected, we monitored whether they were searching for our candidates and whether they were reacting to the information they were finding on social media and where.": 1,
    "Discrimination was happening through social media for equally skilled candidates.": 1,
    " Now, marketers like us to believe that all information about us will always be used in a manner which is in our favor.": 1,
    "But think again, why should that be always the case?": 1,
    " In a movie which came out a few years ago, Minority Report, a famous scene at the Tom Cruise walk in a mall and holographic personalized advertising would appear.": 1,
    " Now, the movie is set in 2054, about 40 years from now, and as exciting as the technology looks, it already vastly underestimates": 1,
    " The amount of information that organizations can gather about you and how they can use it to influence you in a way that you will not even detect.": 1,
    " So, as an example, this is another experiment actually we are running, not yet completed.": 1,
    "Imagine that an organization has access to your list of Facebook friends.": 1,
    "And through some kind of algorithm, they can detect the two friends that you like the most.": 1,
    " And then they create in real time a facial composite of these two friends.": 1,
    "Now studies prior to ours have shown that people don't recognize any longer even themselves in facial composites.": 1,
    " But they react to those composites in a positive manner.": 1,
    "So next time you are looking for a certain product and there is an ad suggesting you to buy it, it will not be just a standard spokesperson.": 1,
    "It will be one of your friends.": 1,
    " And you will not even know that this is happening.": 1,
    "Now, the problem is that the current policy mechanisms we have to protect ourselves from the abuse of information are like bringing a knife to a gunfight.": 1,
    " One of these mechanisms is transparency.": 1,
    "Telling people what you're going to do with their data.": 1,
    "And in principle, that's a very good thing.": 1,
    "It's necessary, but it is not sufficient.": 1,
    "Transparency...": 1,
    " can be misdirected.": 1,
    "You can tell people what you're going to do, and then you still nudge them to disclose arbitrary amounts of personal information.": 1,
    "So in yet another experiment, this one with students.": 1,
    " We asked them to provide information about their campus behavior, including pretty sensitive questions such as this one.": 1,
    "Now, to one group of subjects, we told them, only other students will see your answers.": 1,
    " to another group of subjects, we told them students and faculty will see your answers.": 1,
    "Transparency, notification, and sure enough, this worked.": 1,
    "In a sense, the first group of subjects were much more likely to disclose than the second.": 1,
    "It makes sense, right?": 1,
    " But then we added the misdirection.": 1,
    "We repeated the experiment with the same two groups, this time adding a delay.": 1,
    " between the time we told subjects how we will use their data and the time we actually started answering the questions.": 1,
    " How long a delay do you think we had to add in order to nullify the inhibitory effect of knowing that faculty will see your answers?": 1,
    " Ten minutes?": 1,
    "Five minutes?": 1,
    "One minute?": 1,
    "How about 15 seconds?": 1,
    "15 seconds were sufficient to have the two groups disclose the same amount of information, as if the second group now no longer care for faculty": 1,
    " reading their answers.": 1,
    "Now, I have to admit that these talks so far may sound exceedingly gloomy, but that is not my point.": 1,
    "In fact, I want to share with you the fact that there are alternatives.": 1,
    " The way we are doing things now is not the only way that can be done, and certainly not the best way that can be done.": 1,
    "When someone tells you,": 1,
    " people don't care about privacy, consider whether the game has been designed and rigged so that they cannot care about privacy.": 1,
    "And coming to the realization that these manipulations occur is already halfway through the process of being able to protect yourself.": 1,
    " When someone tells you the privacy is incompatible with the benefits of big data, consider that in the last 20 years, researchers have created technologies": 1,
    " to allow virtually any electronic transactions to take place in a more privacy preserving manner.": 1,
    " We can browse the internet anonymously.": 1,
    "We can send emails that can only be read by the intended recipient, not even the NSA.": 1,
    " we can have even privacy preserving data mining.": 1,
    "In other words, we can have the benefits of big data while protecting privacy.": 1,
    "Of course,": 1,
    " These technologies imply a shifting of costs and revenues between data holders and data subjects, which is why perhaps you don't hear more about them.": 1,
    "Which brings me back to the Garden of Eden.": 1,
    " There is a second privacy interpretation of the story of the Garden of Eden, which doesn't have to do with the issue of Adam and Eve feeling naked and feeling ashamed.": 1,
    " You can find echoes of this interpretation in John Milton's Paradise Lost.": 1,
    " In the garden, Adam and Eve are materially content.": 1,
    "They're happy, they're satisfied.": 1,
    "However, they also lack knowledge and self-awareness.": 1,
    " The moment they eat the aptly named fruit of knowledge, that's when they discover themselves.": 1,
    "They become aware.": 1,
    "They achieve autonomy.": 1,
    "The price to pay, however, is leaving the garden.": 1,
    " So privacy, in a way, is both the means and the price to pay for freedom.": 1,
    " Again, marketers tell us that big data and social media are not just a paradise of profit for them, but a garden for the rest of us.": 1,
    "We get free content, we get to play Angry Birds, we get targeted ads.": 1,
    " But in fact in a few years, organizations will know so much about us that we'll be able to infer our desires before we even form them and perhaps buy products on our behalf before we even know we need them.": 1,
    " Now, there was one English author who anticipated this kind of future where we would trade away our autonomy and freedom for comfort.": 1,
    " Even more so than George Orwell, the author is of course Aldous Huxley.": 1,
    "In Brave New World, imagine a society where technologies that we created originally for freedom end up coercing us.": 1,
    " However, in the book he also offers us a way out of that society, similar to the path that Adam and Eve had to follow to leave the garden.": 1,
    " In the words of the savage, regaining autonomy and freedom is possible, although the price to pay is steep.": 1,
    " So I do believe that one of the defining fights of our times will be the fight for the control over personal information.": 1,
    " the fight over whether big data will become a force for freedom rather than a force which will hiddenly manipulate us.": 1,
    " Right now, many of us do not even know that the fight is going on, but it is, whether you like it or not.": 1,
    " And at the risk of playing the serpent, I will tell you that the tools for the fights are here, the awareness of what is going on, and in your hands.": 1,
    "Just a few clicks away.": 1,
    "Thank you.": 1
  },
  "gender": {
    "male": 118
  },
  "age": {
    "46 - 65": 68,
    "31 - 45": 50
  },
  "emotion": {
    "neutral": 117,
    "happy": 1
  },
  "positivity": {
    "neutral": 118
  },
  "strength": {
    "neutral": 114,
    "strong": 3,
    "weak": 1
  },
  "speaking_rate": {
    "fast": 66,
    "normal": 50,
    "slow": 2
  },
  "hesitation": {
    "no": 118
  },
  "engagement": {
    "neutral": 106,
    "engaged": 12
  },
  "politeness": {
    "polite": 94,
    "neutral": 24
  }
}