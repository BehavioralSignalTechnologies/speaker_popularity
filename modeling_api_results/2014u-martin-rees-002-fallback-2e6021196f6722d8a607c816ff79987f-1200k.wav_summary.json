{
  "diarization": {
    "SPEAKER_00": 71
  },
  "asr": {
    " Ten years ago I wrote a book which I entitled Our Final Century?": 1,
    "My publishers cut out the question mark.": 1,
    " The American publishers changed the title to Our Final Hour.": 1,
    " Americans like instant gratification and the reverse.": 1,
    " And my theme was this.": 1,
    "Our Earth has existed for 45 million centuries, but this one is special.": 1,
    "It's the first when one species, ours, has the planet's future in its hands.": 1,
    " Over nearly all of Earth's history, threats have come from nature, disease, earthquakes, asteroids, and so forth.": 1,
    "But from now on, the worst dangers come from us.": 1,
    " And it's now not just a nuclear threat.": 1,
    " In our interconnected world, network breakdowns can cascade globally.": 1,
    "Air travel can spread pandemics worldwide within days.": 1,
    "And social media can spread panic and rumor literally at the speed of light.": 1,
    " We fret too much about minor hazards.": 1,
    " Improbable air crashes, cost of gens in food, low radiation doses and so forth.": 1,
    "But we and our political masters are in denial about catastrophic scenarios.": 1,
    " The worst have thankfully not yet happened.": 1,
    "Indeed, they probably won't.": 1,
    "But if an event is potentially devastating, it's worth paying a substantial premium to safeguard against it.": 1,
    " even if it's unlikely, just as we take out fire insurance on our house.": 1,
    " And a science offers greater power and promise.": 1,
    " The downside gets scarier, too.": 1,
    "We get ever more vulnerable.": 1,
    " Within a few decades, millions will have the capability to misuse rapidly advancing biotech, just as they misuse cybertech today.": 1,
    " Freeman Dyson, in a TED talk, foresaw that children will design and create new organisms just as routinely as his generation played with chemistry sets.": 1,
    " Well, this may be on the science fiction fringe, but were even part of a scenario to come about, our ecology and even our species would surely not survive long unscathed.": 1,
    " For instance, there are some echo extremists who think that it would be better for the planet, for Gaia, if there were far fewer humans.": 1,
    " What happens when such people have mastered synthetic biology techniques that will be widespread by 2050?": 1,
    " And by then, other science fiction nightmares may transition to reality.": 1,
    "Dumb robots going rogue, or a network that develops a mind of its own, threatens us all.": 1,
    " Well, can we guard against such risks by regulation?": 1,
    " We may surely try, but these enterprises are so competitive, so globalized, and so driven by commercial pressure that anything that can be done will be done somewhere.": 1,
    " whatever the regulations say.": 1,
    "It's like the drug laws, we try to regulate but can't.": 1,
    "And the global village will have its village idiots and they'll have a global rage.": 1,
    " So, as I said in my book, we'll have a bumpy ride through this century.": 1,
    "There may be setbacks to our society.": 1,
    " Indeed, a 50% chance of a severe setback.": 1,
    " But are there conceivable events that could be even worse?": 1,
    "Events that could snuff out all life?": 1,
    " When a new particle accelerator came online, some people anxiously asked, could it destroy the Earth, or even worse, rip apart the fabric of space?": 1,
    "Well, luckily, reassurance could be offered.": 1,
    " I and others pointed out that nature has done the same experiments zillions of times already via cosmic ray collisions.": 1,
    " But scientists should surely be precautionary about experiments that generate conditions without precedent in the natural world.": 1,
    "Biologists should avoid release of potentially devastating genetically modified pathogens.": 1,
    " And by the way, our special aversion to the risk of truly existential disasters depends on the philosophical and ethical question.": 1,
    "And it's this.": 1,
    " Consider two scenarios.": 1,
    "Scenario A wipes out 90% of humanity.": 1,
    " Scenario B wipes out 100%.": 1,
    " How much worse is B than A?": 1,
    " Some would say 10% worse.": 1,
    " The body count is 10% higher.": 1,
    " But I claim that B is incomparably worse.": 1,
    "As an astronomer, I can't believe that humans are the end of the story.": 1,
    " There's five billion years before the sun flares up, and the universe may go on forever.": 1,
    "So, post-human evolution.": 1,
    " here on earth and far beyond could be as prolonged as the Darwinian process has led to us and even more wonderful.": 1,
    " And indeed future evolution will happen much faster on a technological time scale, not a natural selection time scale.": 1,
    "So we surely...": 1,
    " in view of those immense stakes, shouldn't accept even a one in a billion risk that human extinction would foreclose this immense potential.": 1,
    " Some scenarios that have been envisaged may indeed be science fiction, but others may be disquietingly real.": 1,
    " It's an important maxim that the unfamiliar is not the same as the improbable.": 1,
    " And in fact, that's why we at Cambridge University are setting up a centre to study how to mitigate these existential risks.": 1,
    " It seems it's worthwhile just for a few people to think about these potential disasters and we need all the help we can get from others.": 1,
    " because we are stewards of a precious pale blue dot in a vast cosmos, a planet 50 million centuries ahead of it.": 1,
    "And so let's not jeopardize that future.": 1,
    " And I'd like to finish with a quote from the great scientist called Peter Medawar.": 1,
    "I quote, the bells that toll for mankind are like the bells of Alpine cattle.": 1,
    " They are attached to our own necks and it must be our fault if they do not make a tuneful and melodious sound.": 1,
    "Thank you very much.": 1
  },
  "gender": {
    "male": 55
  },
  "age": {
    "46 - 65": 55
  },
  "emotion": {
    "neutral": 53,
    "happy": 2
  },
  "positivity": {
    "neutral": 54,
    "positive": 1
  },
  "strength": {
    "neutral": 50,
    "strong": 5
  },
  "speaking_rate": {
    "normal": 53,
    "fast": 1,
    "slow": 1
  },
  "hesitation": {
    "no": 55
  },
  "engagement": {
    "neutral": 50,
    "engaged": 5
  },
  "politeness": {
    "polite": 55
  }
}