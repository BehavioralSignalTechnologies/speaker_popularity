{
  "diarization": {
    "SPEAKER_00": 197
  },
  "asr": {
    " I want to talk today about, I've been asked to take a long view.": 1,
    " And I'm going to tell you what I think are the three biggest problems for humanity from this long point of view.": 1,
    " Some of these have already been touched upon by other speakers, which is encouraging.": 1,
    "It seems that there's not just one person who thinks that these problems are important.": 1,
    "The first is death is a big problem.": 1,
    " If you look at the statistics, the odds are not very favourable.": 1,
    "So far, most people who have lived have also died.": 1,
    "Roughly 90% of everybody who's been alive has died by now.": 1,
    " Annual death rate adds up to 150,000, sorry the daily death rate, 150,000 people per day.": 1,
    " which is a huge number by any standard, the annual death rate then becomes 56 million.": 1,
    "If we just look at the biggest cause of death, aging,": 1,
    " It accounts for roughly two thirds of all human people who die.": 1,
    "That's up to an annual death toll greater than the population of Canada.": 1,
    " Sometimes we don't see a problem because either it's too familiar or it's too big.": 1,
    "Can't see it because it's too big.": 1,
    "I think death might be both too familiar and too big for most people to see it as a problem.": 1,
    " Once you think about it, this is not statistical points.": 1,
    "Let's see how far I have talked.": 1,
    "I've talked for three minutes, so that would be...": 1,
    " Roughly 324 people have died since I began speaking.": 1,
    "It's roughly the population in this room has just died.": 1,
    " Now, the human cost of that is obvious once you start to think about it, suffering, the loss.": 1,
    "It's also economically enormously wasteful.": 1,
    "Just look at the information and knowledge and experience that is lost.": 1,
    " due to natural causes of death in general, and aging in particular.": 1,
    "Suppose we approximated one person with one book.": 1,
    "Now, of course, this is an underestimation, a person's lifetime of learning and experience.": 1,
    " is a lot more than you could put into a single book.": 1,
    "But let's suppose we did this.": 1,
    " 52,000 people die of natural causes each year.": 1,
    "Corresponds then to 52 million volumes destroyed.": 1,
    "Library of Congress holds 18 million volumes.": 1,
    " We are upset about the burning of the Library of Alexandria.": 1,
    "It's one of the great cultural tragedies that we remember even today.": 1,
    "But this is the equivalent of three libraries of Congress burned down forever, lost each year.": 1,
    " So that's the first big problem and I wish Godspeed to Aubrey de Grey and other people like him to try to do something about this as soon as possible.": 1,
    " Existential risk, the second big problem.": 1,
    "Existential risk is a threat to human survival or to the long-term potential of our species.": 1,
    "Now why do I say that this is a big problem?": 1,
    "Well, let's first look at the": 1,
    " probability.": 1,
    "This is very, very difficult to estimate.": 1,
    "But there have been only four studies on this in recent years, which is surprising.": 1,
    "You would think": 1,
    " that it would be of some interest to try to find out more about this, given that this": 1,
    " The stakes are so big, but it's a very neglected area.": 1,
    "There have been four studies.": 1,
    "One by John Leslie wrote a book on this.": 1,
    "He estimated a probability that we will fail to survive the current century, 50%.": 1,
    " Similarly, the astronomer Royal, whom we heard speak yesterday, also has a 50% probability estimate.": 1,
    " Another author doesn't give a numerical estimate, but says the probability is significant.": 1,
    "That will fail.": 1,
    "I wrote a long paper on this.": 1,
    "I said...": 1,
    " Assigning a less than 20% probability would be a mistake in light of the current evidence we have.": 1,
    "Now, the exact figures here you should take with a big grain of salt, but there seems to be a consensus that": 1,
    " the risk is substantial.": 1,
    "Everybody who has looked at this and studied it agrees.": 1,
    "Now if we think about what just reducing the probability of human extinction by just one percentage point.": 1,
    " Not very much.": 1,
    "So that's equivalent to 60 million lives saved if we just count the currently living people, the current generation.": 1,
    " 1% of 6 billion people, equivalent to 60 million.": 1,
    "So that's a large number.": 1,
    "If we were to take into account future generations,": 1,
    " that will never come into existence if we blow ourselves up, then the figure becomes astronomical.": 1,
    " If we could eventually colonise a chunk of the universe, the Virgo supercluster, maybe it will take us 100 million years to get there, but if we go extinct, we never will.": 1,
    " then even a one percentage point reduction in the extinction risk could be equivalent to this astronomical number, 10 to the power of 32.": 1,
    "So if you take into account future generations as much as our own,": 1,
    " every other moral imperative of philanthropic cause just becomes irrelevant.": 1,
    "The only thing you should focus on would be to reduce existential risk because even the tiniest": 1,
    " decreasing existential risk would just overwhelm any other benefit you could hope to achieve.": 1,
    "And even if you just look at the current people and ignore the potential that would be lost if it went extinct, it should still have a high priority.": 1,
    " Now, let me spend the rest of my time on the third big problem, because it's more subtle and perhaps difficult to grasp.": 1,
    " Think about some time in your life, some people might never have experienced, but some people there are just those moments that you have experienced where life was fantastic.": 1,
    "It might have been": 1,
    " at the moment of some great creative inspiration you might have had when you just entered this flow state, or when you understood something you had never done before, or perhaps in the ecstasy of romantic love.": 1,
    " or an aesthetic experience, sunset, great piece of art.": 1,
    " Every once in a while we have these moments and we realize just how good life can be when it's at its best.": 1,
    "And you wonder, why can't it be like that all the time?": 1,
    "You just want to cling on to this.": 1,
    " And then of course it drifts back into ordinary life and the memory fades and it's really difficult to recall in a normal frame of mind just how good life can be at its best or how bad it can be at its worst.": 1,
    " The third big problem is that life isn't usually as wonderful as it could be.": 1,
    "I think that's a big, big problem.": 1,
    " It's easy to say what we don't want.": 1,
    "There are a number of things that...": 1,
    " We don't want illness, involuntary deaths, unnecessary suffering, cruelty, stunted growth, memory loss, ignorance, absence of creativity.": 1,
    "Suppose we fixed these things.": 1,
    " We did something about all of these.": 1,
    "We were very successful.": 1,
    "We got rid of all of these things.": 1,
    "We might end up with something like this.": 1,
    " which is, I mean, it's a heck of a lot better than that.": 1,
    "But is this really the best we can dream of?": 1,
    "Is this the best we can do?": 1,
    "Or is it possible to find something": 1,
    " a little bit more inspiring to work towards.": 1,
    "And if we think about this, I think it's very clear that there are ways in which we could change things not just by eliminating negatives but adding positives": 1,
    " On my wishlist, at least, would be much longer, healthier lives, greater subjective well-being, enhanced cognitive capacities, more knowledge and understanding.": 1,
    " unlimited opportunity for personal growth beyond our current biological limits, better relationships, and unbounded potential for spiritual, moral, and intellectual development.": 1,
    "If we want to achieve this, what": 1,
    " in the world would have to change?": 1,
    "And this is the answer.": 1,
    " we would have to change, not just the world around us, but we ourselves, not just the way we think about the world, but the way we are, our very biology.": 1,
    " human nature would have to change.": 1,
    "Now when we think about changing human nature, the first thing that comes to mind are these human modification technologies.": 1,
    " growth hormone therapy, cosmetic surgery, stimulants like Ritalin Adderall, antidepressants, anabolic steroids, artificial hearts.": 1,
    "It's a pretty pathetic list.": 1,
    " They do great things for a few people who suffer from some specific condition, but for most people they don't really transform what it is to be human.": 1,
    " And they also all seem a little bit... Most people have this instinct that, well, sure, there needs to be antidepressants for the really depressed people, but there's a kind of queasiness that these are...": 1,
    " unnatural in some way.": 1,
    "It's worth recalling that there are a lot of other modification technologies and enhancement technologies that we use.": 1,
    "We have": 1,
    " skin enhancements, clothing, as far as I can see all of you are users of this enhancement technology in this room.": 1,
    " So that's a great thing.": 1,
    "Mood modifiers have been used from time immemorial, caffeine, alcohol, nicotine, immune system enhancement.": 1,
    " vision enhancement, and aesthetics.": 1,
    "We take that very much for granted, but just think about how great progress that is.": 1,
    " having an operation before anesthetics was not fun.": 1,
    "Contraceptives, cosmetics, and brain reprogramming techniques that sounds ominous, but": 1,
    " the distinction between what is a technology, the gadget would be the archetype, and other ways of changing and rewriting human nature is quite subtle.": 1,
    " If you think about what it means to learn arithmetic or to learn to read, you're actually literally rewriting your own brain.": 1,
    "You're changing the microstructure of your brain as you go along.": 1,
    "So in a broad sense,": 1,
    " We don't need to think about technologies only as little gadgets like these things here, but even institutions and techniques, psychological methods and so forth, forms of organization.": 1,
    " can have a profound impact on human nature.": 1,
    "Looking ahead, there is a range of technologies that are almost certain to be developed sooner or later.": 1,
    "We are very ignorant about what the time scale for these things are.": 1,
    " but they all are consistent with everything we know about physical laws, laws of chemistry, etc.": 1,
    "It's possible to assume": 1,
    " setting aside the possibility of catastrophe that sooner or later we will develop all of these.": 1,
    " a couple of these would be enough to transform the human condition.": 1,
    "Let's look at some of the dimensions of human nature that": 1,
    " seem to leave room for improvement.": 1,
    "Healthspan is a big and urgent thing, because if you're not alive, then all the other things will be to little avail.": 1,
    "Intellectual capacity, let's take that box.": 1,
    " falls into a lot of different sub-categories.": 1,
    "Memory, concentration, mental energy, intelligence, empathy.": 1,
    "These are really great things.": 1,
    "Part of the reason why we value these traits is": 1,
    " that they make us better at competing with other people, their positional goods.": 1,
    "But part of the reason, and that's the reason why we have an ethical ground for pursuing this, is that they're also intrinsically valuable.": 1,
    " It's just better to be able to understand more of the world around you and the people that you're communicating with and to remember what you have learned.": 1,
    " modalities and special faculties.": 1,
    "The human mind is not a single unitary information processor, but it has a lot of different special": 1,
    " evolved modules that do specific things for us.": 1,
    "If you think about what we normally take as giving life a lot of its meaning, music, humour, eroticism, spirituality, aesthetics, nurturing and caring,": 1,
    " gossip, chatting with people.": 1,
    "All of these very likely are enabled by a special circuitry that we humans have, but that you could have another intelligent life form that lacked these.": 1,
    "We're just lucky that we have": 1,
    " the requisite neural machinery to process music and to appreciate it and enjoy it.": 1,
    "All of these would in principle be amenable to enhancement.": 1,
    "Some people have better musical ability and ability to appreciate music than others have.": 1,
    " It's also interesting to think about what other things are.": 1,
    "So if these all enable great values,": 1,
    " Why should we think that evolution has happened to provide us with all the modalities we would need to engage with other values that there might be?": 1,
    "Imagine a species that just didn't have this neural machinery for processing music.": 1,
    " And they would just stare at us with bafflement when we spent time listening to beautiful performance like the one we just heard.": 1,
    "There's people making stupid movements and they would be really irritated and don't see what we were up to.": 1,
    " Maybe they have another faculty, something else that would seem equally irrational to us, but they actually tap into some great possible value there.": 1,
    "But we are just literally deaf to that kind of value.": 1,
    " Think of adding on different new sensory capacities and mental faculties.": 1,
    "Bodily functionality and morphology.": 1,
    "And effective self-control, greater subjective well-being.": 1,
    " be able to switch between relaxation and activity, being able to go slow when you need to do that, and then to speed up.": 1,
    "Be able to switch back and forth more easily would be a neat": 1,
    " thing to be able to do.": 1,
    "Easier to achieve the flow state when you're totally immersed in something you're doing.": 1,
    "Conscientiousness and sympathy, ability to": 1,
    " It's another interesting application that would have large social ramification.": 1,
    "If you could actually...": 1,
    " choose to preserve your romantic attachments to one person undiminished through time so that love would never have to fade if you didn't want it to.": 1,
    " That's probably not all that difficult.": 1,
    "It might just be a simple hormone or something that could do this.": 1,
    " It's been done in voles.": 1,
    "You can engineer a prairie vole to become monogamous when it's naturally polygamous.": 1,
    "It's just a single gene.": 1,
    "It might be more complicated in humans, but perhaps not that much.": 1,
    "This is the last picture I want to end.": 1,
    " Now I'm going to use laser pointer.": 1,
    " possible mode of being here would be a way of life, a way of being, experiencing, thinking, seeing, interacting with the world.": 1,
    "Down here in this little corner here, we have": 1,
    " the little subspace of this larger space that is accessible to human beings, beings with our biological capacities.": 1,
    " It's a part of the space that's accessible to animals, since we are animals, we are a subset of that.": 1,
    "And then you can imagine some enhancements of human capacities.": 1,
    " there would be different modes of beings you could experience if you were able to stay alive for say two hundred years then you could live sorts of lives and accumulate wisdoms that are just not": 1,
    " Possible for humans as we currently are so then you move up to this larger sphere of human plus and you could continue that process": 1,
    " and eventually explore a lot of this larger space of possible modes of beings.": 1,
    "Now why is that a good thing to do?": 1,
    "Well, we know already that in this little human circle there,": 1,
    " There are these enormously wonderful and worthwhile modes of being.": 1,
    "Human life at its best is wonderful.": 1,
    "We have no reason to believe": 1,
    " that within this much, much larger space there would not also be extremely worthwhile modes of being.": 1,
    "Perhaps ones that would be way beyond our wildest ability even to imagine or dream about.": 1,
    " And so to fix this third problem, I think we need slowly, carefully, with ethical wisdom and constraint, develop the means": 1,
    " that enable us to go out in this larger space and explore it and find the great values that might hide there.": 1,
    "Thanks.": 1
  },
  "gender": {
    "male": 148
  },
  "age": {
    "31 - 45": 79,
    "46 - 65": 68,
    "18 - 22": 1
  },
  "emotion": {
    "neutral": 139,
    "happy": 9
  },
  "positivity": {
    "neutral": 145,
    "positive": 3
  },
  "strength": {
    "neutral": 140,
    "strong": 8
  },
  "speaking_rate": {
    "normal": 76,
    "fast": 69,
    "slow": 3
  },
  "hesitation": {
    "no": 145,
    "yes": 3
  },
  "engagement": {
    "neutral": 139,
    "engaged": 9
  },
  "politeness": {
    "polite": 138,
    "neutral": 10
  }
}